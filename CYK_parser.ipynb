{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAA Package.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQKhf0Q8pwWQ"
      },
      "source": [
        "## **CYK Algorithm - Parsing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnJIkNhB5usM"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HReqZWIz5yJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb63c40c-dbe1-4fe2-9b4c-4fbaf06987b7"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfoGqyhF5_uV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c19e86-633c-4ab5-afa9-8d437bf43803"
      },
      "source": [
        "!pip install treelib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting treelib\n",
            "  Downloading https://files.pythonhosted.org/packages/04/b0/2269c328abffbb63979f7143351a24a066776b87526d79956aea5018b80a/treelib-1.6.1.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from treelib) (0.16.0)\n",
            "Building wheels for collected packages: treelib\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-cp36-none-any.whl size=18369 sha256=eeba6dbda6585acb0b402c83fa1105cff753b6267c9ae102c841b351b1f93e5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/1d/92/c50ec52951ccebafb40f3b8f0beb28fbaf745431c14a17c497\n",
            "Successfully built treelib\n",
            "Installing collected packages: treelib\n",
            "Successfully installed treelib-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHwPsTED567S"
      },
      "source": [
        "import nltk\n",
        "import json\n",
        "from nltk import PCFG,Production,nonterminals, Nonterminal\n",
        "from treelib import Node, Tree\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pF9-VKFmlx_"
      },
      "source": [
        "# 1.Context Free Grammar to Chomsky Normal Form Convertion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toBBD5fUmySk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a20139-6526-4fdd-c218-a701d28e2c1e"
      },
      "source": [
        "# Global dictionary used for storing the rules.\n",
        "from treelib import Node, Tree\n",
        "RULE_DICT = {}\n",
        "\n",
        "\n",
        "def read_grammar(grammar_file):\n",
        "    \"\"\"\n",
        "    Reads in the given grammar file and splits it into separate lists for each rule.\n",
        "    :param grammar_file: the grammar file to read in.\n",
        "    :return: the list of rules.\n",
        "    \"\"\"\n",
        "    with open(grammar_file) as cfg:\n",
        "        lines = cfg.readlines()\n",
        "    return [x.replace(\"->\", \"\").split() for x in lines]\n",
        "\n",
        "\n",
        "def add_rule(rule):\n",
        "    \"\"\"\n",
        "    Adds a rule to the dictionary of lists of rules.\n",
        "    :param rule: the rule to add to the dict.\n",
        "    \"\"\"\n",
        "    global RULE_DICT\n",
        "    \n",
        "    if rule[0] not in RULE_DICT:\n",
        "        RULE_DICT[rule[0]] = []\n",
        "    RULE_DICT[rule[0]].append(rule[1:])\n",
        "\n",
        "\n",
        "def convert_grammar(grammar):\n",
        "    \"\"\"\n",
        "        Converts a context-free grammar in the form of\n",
        "\n",
        "        S -> NP VP\n",
        "        NP -> Det ADV N\n",
        "\n",
        "        and so on into a chomsky normal form of that grammar. After the conversion rules have either\n",
        "        exactly one terminal symbol or exactly two non terminal symbols on its right hand side.\n",
        "\n",
        "        Therefore some new non terminal symbols might be created. These non terminal symbols are\n",
        "        named like the symbol they replaced with an appended index.\n",
        "    :param grammar: the CFG.\n",
        "    :return: the given grammar converted into CNF.\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove all the productions of the type A -> X B C or A -> B a.\n",
        "    global RULE_DICT\n",
        "    unit_productions, result = [], []\n",
        "    res_append = result.append\n",
        "    index = 0\n",
        "\n",
        "    for rule in grammar:\n",
        "        new_rules = []\n",
        "        if len(rule) == 2 and rule[1][0] != \"'\":\n",
        "            # Rule is in form A -> X, so back it up for later and continue with the next rule.\n",
        "            unit_productions.append(rule)\n",
        "            add_rule(rule)\n",
        "            continue\n",
        "        elif len(rule) > 2:\n",
        "            # Rule is in form A -> X B C [...] or A -> X a.\n",
        "            terminals = [(item, i) for i, item in enumerate(rule) if item[0] == \"'\"]\n",
        "            if terminals:\n",
        "                for item in terminals:\n",
        "                    # Create a new non terminal symbol and replace the terminal symbol with it.\n",
        "                    # The non terminal symbol derives the replaced terminal symbol.\n",
        "                    rule[item[1]] = f\"{rule[0]}{str(index)}\"\n",
        "                    new_rules += [f\"{rule[0]}{str(index)}\", item[0]]\n",
        "                index += 1\n",
        "            while len(rule) > 3:\n",
        "                new_rules.append([f\"{rule[0]}{str(index)}\", rule[1], rule[2]])\n",
        "                rule = [rule[0]] + [f\"{rule[0]}{str(index)}\"] + rule[3:]\n",
        "                index += 1\n",
        "        # Adds the modified or unmodified (in case of A -> x i.e.) rules.\n",
        "        add_rule(rule)\n",
        "        res_append(rule)\n",
        "        if new_rules:\n",
        "            result.extend(new_rules)\n",
        "    # Handle the unit productions (A -> X)\n",
        "    while unit_productions:\n",
        "        rule = unit_productions.pop()\n",
        "        if rule[1] in RULE_DICT:\n",
        "            for item in RULE_DICT[rule[1]]:\n",
        "                new_rule = [rule[0]] + item\n",
        "                if len(new_rule) > 2 or new_rule[1][0] == \"'\":\n",
        "                    res_append(new_rule)\n",
        "                else:\n",
        "                    unit_productions.append(new_rule)\n",
        "                add_rule(new_rule)\n",
        "    return result\n",
        "\n",
        "with open('grammar.txt') as f:\n",
        "        grammar = [line.rstrip('\\n') for line in f]\n",
        "grammar = [x.replace(\"-> \",\"\").split() for x in grammar]\n",
        "\n",
        "#Rules of the grammar\n",
        "rules = convert_grammar(grammar)\n",
        "print(rules)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['S', 'NP', 'VP'], ['S', 'S0', 'VP'], ['S0', 'NP', 'NP'], ['NP', 'DT', 'NN'], ['NP', 'NP', 'PP'], ['NP', 'NP1', 'NN'], ['NP1', 'DT', 'NN'], ['VP', 'V', 'NP'], ['VP', 'VP2', 'PP'], ['VP2', 'V', 'NP'], ['PP', 'IN', 'NP'], ['DT', \"'my'\"], ['DT', \"'a'\"], ['DT', \"'the'\"], ['DT', \"'an'\"], ['DT', \"'this'\"], ['DT', \"'that'\"], ['NN', \"'I'\"], ['NN', \"'elephant'\"], ['NN', \"'pajamas'\"], ['NN', \"'dog'\"], ['NN', \"'man'\"], ['NN', \"'burglar'\"], ['NN', \"'apartment'\"], ['NN', \"'Boeing'\"], ['NN', \"'Seattle'\"], ['NN', \"'IBM'\"], ['NN', \"'book'\"], ['NN', \"'orange'\"], ['NN', \"'he'\"], ['NN', \"'street'\"], ['NN', \"'car'\"], ['NN', \"'park'\"], ['NN', \"'Smith'\"], ['NN', \"'Gates'\"], ['NN', \"'telephone'\"], ['NN', \"'house'\"], ['NN', \"'building'\"], ['NN', \"'box'\"], ['NN', \"'mechanic'\"], ['NN', \"'pigeon'\"], ['IN', \"'in'\"], ['IN', \"'down'\"], ['IN', \"'of'\"], ['IN', \"'out'\"], ['IN', \"'up'\"], ['IN', \"'beside'\"], ['IN', \"'above'\"], ['IN', \"'as'\"], ['IN', \"'under'\"], ['IN', \"'on'\"], ['IN', \"'with'\"], ['V', \"'is'\"], ['V', \"'shot'\"], ['V', \"'located'\"], ['V', \"'laughs'\"], ['V', \"'sleeps'\"], ['V', \"'robbed'\"], ['V', \"'bought'\"], ['V', \"'saw'\"], ['V', \"'drove'\"], ['V', \"'walk'\"], ['V', \"'gives'\"], ['V', \"'gave'\"], ['V', \"'sees'\"], ['V', \"'likes'\"]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH1llntennvs"
      },
      "source": [
        "# 2. CYK Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7_wit1OnWEe"
      },
      "source": [
        "def recognise_CYK(w,list1):\n",
        "    # Function to perform the CYK Algorithm \n",
        "    def cykParse(w,R): \n",
        "    \tn = len(w) \n",
        "    \t\n",
        "    \t# Initialize the table \n",
        "    \tT = [[set([]) for j in range(n)] for i in range(n)] \n",
        "    \n",
        "    \t# Filling in the table \n",
        "    \tfor j in range(0, n): \n",
        "    \n",
        "    \t\t# Iterate over the rules \n",
        "            for lhs, rule in R.items(): \n",
        "                for rhs in rule: \n",
        "                      \n",
        "                    # If a terminal is found \n",
        "                    if len(rhs) == 1 and rhs[0] == w[j]: \n",
        "                        T[j][j].add(lhs) \n",
        "      \n",
        "            for i in range(j, -1, -1):    \n",
        "                   \n",
        "                # Iterate over the range i to j + 1    \n",
        "                for k in range(i, j + 1):      \n",
        "      \n",
        "                    # Iterate over the rules \n",
        "                    for lhs, rule in R.items(): \n",
        "                        for rhs in rule: \n",
        "                              \n",
        "                            # If a terminal is found \n",
        "                            if len(rhs) == 2 and rhs[0] in T[i][k] and (k < n-1) and rhs[1] in T[k + 1][j]: \n",
        "                                T[i][j].add(lhs)\n",
        "    \n",
        "    \t# If word can be formed by rules \n",
        "    \t# of given grammar \n",
        "    \tif len(T[0][n-1]) != 0: \n",
        "    \t\t return \"True\" \n",
        "    \treturn \"False\"\n",
        "    \t\n",
        "    \n",
        "    R = {}\n",
        "        \n",
        "    for i in list1:\n",
        "        index = 0\n",
        "        for j in i:\n",
        "            if index == 0:\n",
        "                index = j\n",
        "                if j not in R.keys():\n",
        "                    R[j]=[]\n",
        "            else:\n",
        "                R[index].append([i[x] for x in range(1,len(i))])\n",
        "                break\n",
        "    \n",
        "    # Function Call \n",
        "    check = cykParse(w,R) \n",
        "    return check\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMQlGrZI6UZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36a5a89-8519-4e19-e44e-58203af19223"
      },
      "source": [
        "with open('grammar.txt') as f:\n",
        "        grammar = [line.rstrip('\\n') for line in f]\n",
        "grammar = [x.replace(\"-> \",\"\").split() for x in grammar]\n",
        "\n",
        "#Rules of the grammar\n",
        "rules = convert_grammar(grammar)\n",
        "rules = [[x.replace(\"'\",\"\") for x in l] for l in rules]\n",
        "sentence = \"a burglar robbed the apartment\"\n",
        "result = recognise_CYK(sentence.split(),rules)\n",
        "print(sentence,\"--\",result)\n",
        "\n",
        "sentence = \"a man is sleeping\"\n",
        "result = recognise_CYK(sentence.split(),rules)\n",
        "print(sentence,\"--\",result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a burglar robbed the apartment -- True\n",
            "a man is sleeping -- False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-JNaGhT6II3"
      },
      "source": [
        "# 3. CYK Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uBodtIwiUz2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpsUKAK1oT_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0c78a0-3538-43d0-cdd8-1333f8db855c"
      },
      "source": [
        "import os.path\n",
        "import argparse\n",
        "\n",
        "\n",
        "\n",
        "class Node_:\n",
        "    \"\"\"\n",
        "    Used for storing information about a non-terminal symbol. A node can have a maximum of two\n",
        "    children because of the CNF of the grammar.\n",
        "    It is possible though that there are multiple parses of a sentence. In this case information\n",
        "    about an alternative child is stored in self.child1 or self.child2 (the parser will decide\n",
        "    where according to the ambiguous rule).\n",
        "    Either child1 is a terminal symbol passed as string, or both children are Nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol, child1, child2=None):\n",
        "        self.symbol = symbol\n",
        "        self.child1 = child1\n",
        "        self.child2 = child2\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        :return: the string representation of a Node_ object.\n",
        "        \"\"\"\n",
        "        return self.symbol\n",
        "\n",
        "\n",
        "class Parser:\n",
        "    \"\"\"\n",
        "    A CYK parser which is able to parse any grammar in CNF. The grammar can be read from a file or\n",
        "    passed as a string. It either returns a string representation of the parse tree(s) or prints it\n",
        "    to standard out.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, grammar, sentence):\n",
        "        \"\"\"\n",
        "        Creates a new parser object which will read in the grammar and transform it into CNF and\n",
        "        then parse the given sentence with that grammar.\n",
        "        :param grammar: the file path to the grammar/the string repr. of the grammar to read in\n",
        "        :param sentence: the file path to the sentence/the string repr. of the sentence to read in\n",
        "        \"\"\"\n",
        "        self.parse_table = None\n",
        "        self.prods = {}\n",
        "        self.grammar = None\n",
        "        if os.path.isfile(grammar):\n",
        "            self.grammar_from_file(grammar)\n",
        "        else:\n",
        "            self.grammar_from_string(grammar)\n",
        "        self.__call__(sentence)\n",
        "\n",
        "    def __call__(self, sentence, parse=False):\n",
        "        \"\"\"\n",
        "        Parse the given sentence (string or file) with the earlier given grammar.\n",
        "        :param sentence: the sentence to parse with self.grammar\n",
        "        \"\"\"\n",
        "        if os.path.isfile(sentence):\n",
        "            with open(sentence) as inp:\n",
        "                self.input = inp.readline().split()\n",
        "                if parse:\n",
        "                    self.parse()\n",
        "        else:\n",
        "            self.input = sentence.split()\n",
        "\n",
        "    def grammar_from_file(self, grammar):\n",
        "        \"\"\"\n",
        "        Reads in a CFG from a given file, converts it to CNF and stores it in self.grammar.\n",
        "        :param grammar: the file in which the grammar is stored.\n",
        "        \"\"\"\n",
        "        self.grammar = convert_grammar(read_grammar(grammar))\n",
        "\n",
        "    def grammar_from_string(self, grammar):\n",
        "        \"\"\"\n",
        "        Reads in a CFG from a string, converts it to CNF and stores it in self.grammar.\n",
        "        :param grammar: the CFG in string representation.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.grammar = convert_grammar([x.replace(\"->\", \"\").split() for x in grammar.split(\"\\n\")])\n",
        "\n",
        "    def parse(self):\n",
        "        \"\"\"\n",
        "        Does the actual parsing according to the CYK algorithm. The parse table is stored in\n",
        "        self.parse_table.\n",
        "        \"\"\"\n",
        "        length = len(self.input)\n",
        "        # self.parse_table[y][x] is the list of nodes in the x+1 cell of y+1 row in the table.\n",
        "        # That cell covers the word below it and y more words after.\n",
        "        self.parse_table = [[[] for x in range(length - y)] for y in range(length)]\n",
        "\n",
        "        for i, word in enumerate(self.input):\n",
        "            # Find out which non terminals can generate the terminals in the input string\n",
        "            # and put them into the parse table. One terminal could be generated by multiple\n",
        "            # non terminals, therefore the parse table will contain a list of non terminals.\n",
        "            for rule in self.grammar:\n",
        "                if f\"'{word}'\" == rule[1]:\n",
        "                    self.parse_table[0][i].append(Node_(rule[0], word))\n",
        "        for words_to_consider in range(2, length + 1):\n",
        "            for starting_cell in range(0, length - words_to_consider + 1):\n",
        "                for left_size in range(1, words_to_consider):\n",
        "                    right_size = words_to_consider - left_size\n",
        "\n",
        "                    left_cell = self.parse_table[left_size - 1][starting_cell]\n",
        "                    right_cell = self.parse_table[right_size - 1][starting_cell + left_size]\n",
        "\n",
        "                    for rule in self.grammar:\n",
        "                        left_nodes = [n for n in left_cell if n.symbol == rule[1]]\n",
        "                        if left_nodes:\n",
        "                            right_nodes = [n for n in right_cell if n.symbol == rule[2]]\n",
        "                            self.parse_table[words_to_consider - 1][starting_cell].extend(\n",
        "                                [Node_(rule[0], left, right) for left in left_nodes for right in right_nodes]\n",
        "                            )\n",
        "\n",
        "    def print_tree(self, output=True):\n",
        "        \"\"\"\n",
        "        Print the parse tree starting with the start symbol. Alternatively it returns the string\n",
        "        representation of the tree(s) instead of printing it.\n",
        "        \"\"\"\n",
        "        start_symbol = self.grammar[0][0]\n",
        "        final_nodes = [n for n in self.parse_table[-1][0] if n.symbol == start_symbol]\n",
        "        if final_nodes:\n",
        "            #print(final_nodes)\n",
        "            trees = [generate_tree(node) for node in final_nodes]\n",
        "            print(trees[0])\n",
        "            root, *tail = trees[0]\n",
        "            tree = Tree()\n",
        "\n",
        "            node = Node(root)\n",
        "            tree.add_node(node)\n",
        "\n",
        "            q = [[node, *tail]]\n",
        "            while q:\n",
        "              parent, *children = q.pop()\n",
        "              for child in children:\n",
        "                  if isinstance(child, list):\n",
        "                      head, *tail = child\n",
        "                      node = tree.create_node(head, parent=parent)\n",
        "                      q.append([node, *tail])\n",
        "                  else:\n",
        "                      tree.create_node(child, parent=parent)\n",
        "\n",
        "            tree.show()\n",
        "\n",
        "            #if output:\n",
        "             #   for tree in trees:\n",
        "              #      print(tree)\n",
        "            #else:\n",
        "             #   return trees\n",
        "        \n",
        "def generate_tree(node):\n",
        "    \"\"\"\n",
        "    Generates the string representation of the parse tree.\n",
        "    :param node: the root node.\n",
        "    :return: the parse tree in string form.\n",
        "    \"\"\"\n",
        "    if node.child2 is None:\n",
        "        return [node.symbol ,node.child1]\n",
        "    return [node.symbol,generate_tree(node.child1),generate_tree(node.child2)]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    grammarP = 'grammar.txt'\n",
        "    with open('grammar.txt') as f:\n",
        "        grammar = [line.rstrip('\\n') for line in f]\n",
        "    grammar = [x.replace(\"-> \",\"\").split() for x in grammar]\n",
        "\n",
        "    #Rules of the grammar\n",
        "    rules = convert_grammar(grammar)\n",
        "    rules = [[x.replace(\"'\",\"\") for x in l] for l in rules]\n",
        "    sentence = \"a burglar robbed the apartment\"\n",
        "    result = recognise_CYK(sentence.split(),rules)\n",
        "    print(sentence,\"--\",result)\n",
        "\n",
        "    \n",
        "    if(result==\"True\"):\n",
        "      sentence = 'sentence.txt'\n",
        "      print(\"The given sentence is contained in the language produced by the given grammar!\")\n",
        "      print(\"\\nPossible parse(s):\")\n",
        "      CYK = Parser(grammarP, sentence)\n",
        "      CYK.parse()\n",
        "      CYK.print_tree()\n",
        "    else:\n",
        "      print(\"The given sentence is not contained in the language produced by the given grammar!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a burglar robbed the apartment -- True\n",
            "The given sentence is contained in the language produced by the given grammar!\n",
            "\n",
            "Possible parse(s):\n",
            "['S', ['NP', ['DT', 'a'], ['NN', 'burglar']], ['VP', ['V', 'robbed'], ['NP', ['DT', 'the'], ['NN', 'apartment']]]]\n",
            "S\n",
            "├── NP\n",
            "│   ├── DT\n",
            "│   │   └── a\n",
            "│   └── NN\n",
            "│       └── burglar\n",
            "└── VP\n",
            "    ├── NP\n",
            "    │   ├── DT\n",
            "    │   │   └── the\n",
            "    │   └── NN\n",
            "    │       └── apartment\n",
            "    └── V\n",
            "        └── robbed\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdpkMcRd7KVn"
      },
      "source": [
        "# 4. Probabilistic CYK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXzU1CR8zvmc"
      },
      "source": [
        "pcfg = PCFG.fromstring(\"\"\"S -> NP VP [1.0]\n",
        "                          NP -> DT NN [0.5]\n",
        "                          NP -> NP PP [0.25]\n",
        "                          NP -> 'John' [0.1]\n",
        "                          NP -> 'I' [0.15]\n",
        "                          PP -> P NP [1.0]\n",
        "                          VP -> V [0.4]\n",
        "                          VP -> Vt NP [0.4]\n",
        "                          VP -> VP PP [0.2]\n",
        "                          V -> 'sleeps' [1.0]\n",
        "                          Vt -> 'saw' [0.7]\n",
        "                          Vt -> 'ate' [0.3]\n",
        "                          P -> 'with' [0.7]\n",
        "                          P -> 'under' [0.3]\n",
        "                          DT -> 'the' [0.7]\n",
        "                          DT -> 'a' [0.3]\n",
        "                          NN -> 'man' [0.7]\n",
        "                          NN -> 'dog' [0.2]\n",
        "                          NN -> 'telescope' [0.1]\n",
        "                        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v7VJUMD7d-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77acef12-35b7-4991-8373-84fb22d0a20f"
      },
      "source": [
        "print(pcfg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grammar with 19 productions (start state = S)\n",
            "    S -> NP VP [1.0]\n",
            "    NP -> DT NN [0.5]\n",
            "    NP -> NP PP [0.25]\n",
            "    NP -> 'John' [0.1]\n",
            "    NP -> 'I' [0.15]\n",
            "    PP -> P NP [1.0]\n",
            "    VP -> V [0.4]\n",
            "    VP -> Vt NP [0.4]\n",
            "    VP -> VP PP [0.2]\n",
            "    V -> 'sleeps' [1.0]\n",
            "    Vt -> 'saw' [0.7]\n",
            "    Vt -> 'ate' [0.3]\n",
            "    P -> 'with' [0.7]\n",
            "    P -> 'under' [0.3]\n",
            "    DT -> 'the' [0.7]\n",
            "    DT -> 'a' [0.3]\n",
            "    NN -> 'man' [0.7]\n",
            "    NN -> 'dog' [0.2]\n",
            "    NN -> 'telescope' [0.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2S96F-p7jLU"
      },
      "source": [
        "class PCFGParser():\n",
        "    \n",
        "    \n",
        "    def __init__(self,grammar):\n",
        "        \n",
        "        #Initialize Nonterminals and the Unary and Binary rules\n",
        "        \n",
        "        self.unary_rules = []\n",
        "        self.binary_rules =[]\n",
        "        self.N =['S','NP','PP','VP','V','Vt','P','DT','NN']  \n",
        "        self.rules =[]\n",
        "\n",
        "        \n",
        "        for rule in grammar.productions():\n",
        "            \n",
        "            self.rules.append(rule)\n",
        "            \n",
        "            if len(rule)==1:\n",
        "                self.unary_rules.append(rule)\n",
        "            elif len(rule)==2:\n",
        "                self.binary_rules.append(rule)\n",
        "    \n",
        "    def q(self, X , Y, Z):\n",
        "        \n",
        "        #Returns probabilities for Binary rules\n",
        "        \n",
        "        \n",
        "        if(Y==Z):\n",
        "            for rule in self.rules:\n",
        "                if len(rule)==1:\n",
        "                    if str(rule.rhs()[0]) in N:\n",
        "                        return rule.prob()\n",
        "        \n",
        "        \n",
        "        for rule in self.binary_rules:\n",
        "            if str(rule.lhs())==X and str(rule.rhs()[0])==Y and str(rule.rhs()[1])==Z:\n",
        "            \n",
        "                return rule.prob()\n",
        "            \n",
        "        return 0\n",
        "\n",
        "    def q_unary(self, X, W):\n",
        "        \n",
        "        #Returns probabilities for Unary rules\n",
        "        \n",
        "        for rule in self.unary_rules:\n",
        "            if str(rule.lhs())==X and rule.rhs()[0]==W:\n",
        "                return rule.prob()\n",
        "        return 0\n",
        "    \n",
        "    \n",
        "    def parse(self, sentence):\n",
        "        \n",
        "        #Calls the CYK Algorithm and stores the parse tree in a JSON Format\n",
        "        \n",
        "        sentence  = sentence.strip()\n",
        "        parse_output = json.dumps(self.CKY(sentence.split(' ')))\n",
        "        #print (json.dumps(self.CKY(sentence.split(' '))))\n",
        "        parse_tree = json.loads(parse_output)\n",
        "        print(parse_tree)\n",
        "        \n",
        "        root, *tail = parse_tree\n",
        "        tree = Tree()\n",
        "        node = Node(root)\n",
        "        tree.add_node(node)\n",
        "\n",
        "        q = [[node, *tail]]\n",
        "        while q:\n",
        "            parent, *children = q.pop()\n",
        "            for child in children:\n",
        "                if isinstance(child, list):\n",
        "                    head, *tail = child\n",
        "                    node = tree.create_node(head, parent=parent)\n",
        "                    q.append([node, *tail])\n",
        "                else:\n",
        "                    tree.create_node(child, parent=parent)\n",
        "\n",
        "        tree.show()\n",
        "        \n",
        "        \n",
        "                \n",
        "    def CKY(self, x):\n",
        "        \n",
        "        #Returns Tree for a grammar in Chomsky-Normal Form \n",
        "        \n",
        "        n = len(x) # length of sentence x\n",
        "        pi = defaultdict(float) # DP table pi\n",
        "        bp = {} # back pointers\n",
        "\n",
        "        # Base case\n",
        "        for i in range(n):\n",
        "            w = x[i] \n",
        "            for X in self.N:\n",
        "                pi[i, i, X] = self.q_unary(X, w) \n",
        "                #Handle Unary rules ending with Non-terminals\n",
        "                if n <=3:\n",
        "                    if pi[i,i,X]:\n",
        "                        for rule in self.rules:\n",
        "                            if len(rule)==1:\n",
        "                                if str(rule.rhs()[0])==X:\n",
        "                                    pi[i,i,str(rule.lhs())] = rule.prob()\n",
        "        \n",
        "        # Recursive case\n",
        "        for l in range(1, n): \n",
        "            for i in range(n-l):\n",
        "                j = i + l\n",
        "                for X in self.N:\n",
        "                    max_score = 0\n",
        "                    args = None\n",
        "                    for R in self.binary_rules: # search only within the rules with non-zero probability\n",
        "                        \n",
        "                        \n",
        "                        if str(R.lhs()) == X: # consider rules which start from X\n",
        "                            Y,Z= R.rhs()\n",
        "                            Y = str(Y)\n",
        "                            Z = str(Z)\n",
        "                            for s in range(i, j):\n",
        "                                        \n",
        "                                if pi[i, s, Y] and pi[s + 1, j, Z]: # calculate score if both pi entries have non-zero score\n",
        "                                    score = self.q(X, Y, Z) * pi[i, s, Y] * pi[s + 1, j, Z]\n",
        "                                    if max_score < score:\n",
        "                                        max_score = score\n",
        "                                        args = Y, Z, s\n",
        "                                            \n",
        "                                            \n",
        "                    if max_score: # update table and back pointers\n",
        "                        pi[i, j, X] = max_score\n",
        "                        bp[i, j, X] = args\n",
        "\n",
        "        # Backtrack to retrieve the tree\n",
        "        if pi[0, n-1, 'S']:\n",
        "            return self.backtrack_tree(x, bp, 0, n-1, 'S')\n",
        "        else: # if start symbol is not 'S'\n",
        "            max_score = 0\n",
        "            args = None\n",
        "            for X in self.N:\n",
        "                print(pi[0, n-1, X])\n",
        "                if max_score < pi[0, n-1, X]:\n",
        "                    max_score = pi[0, n-1, X]\n",
        "                    args = 0, n-1, X\n",
        "            return self.backtrack_tree(x, bp, *args)\n",
        "        \n",
        "        \n",
        "        \n",
        "     \n",
        "    def backtrack_tree(self, sentence, bp, i, j, X):\n",
        "       #Recurse to get the parse tree\n",
        "        if i == j:\n",
        "            return [X, sentence[i]]\n",
        "        else:\n",
        "            Y, Z, s = bp[i, j, X]\n",
        "            return [X, self.backtrack_tree(sentence, bp, i, s, Y), \n",
        "                       self.backtrack_tree(sentence, bp, s+1, j, Z)]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH-nPHEI7v9x"
      },
      "source": [
        "parser = PCFGParser(pcfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fabAJWd7yJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d09696-a344-4e9b-d751-60d45e808670"
      },
      "source": [
        "parser.parse('the dog saw the man with the telescope')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['S', ['NP', ['DT', 'the'], ['NN', 'dog']], ['VP', ['Vt', 'saw'], ['NP', ['NP', ['DT', 'the'], ['NN', 'man']], ['PP', ['P', 'with'], ['NP', ['DT', 'the'], ['NN', 'telescope']]]]]]\n",
            "S\n",
            "├── NP\n",
            "│   ├── DT\n",
            "│   │   └── the\n",
            "│   └── NN\n",
            "│       └── dog\n",
            "└── VP\n",
            "    ├── NP\n",
            "    │   ├── NP\n",
            "    │   │   ├── DT\n",
            "    │   │   │   └── the\n",
            "    │   │   └── NN\n",
            "    │   │       └── man\n",
            "    │   └── PP\n",
            "    │       ├── NP\n",
            "    │       │   ├── DT\n",
            "    │       │   │   └── the\n",
            "    │       │   └── NN\n",
            "    │       │       └── telescope\n",
            "    │       └── P\n",
            "    │           └── with\n",
            "    └── Vt\n",
            "        └── saw\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}